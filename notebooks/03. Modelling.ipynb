{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb9aca",
   "metadata": {},
   "source": [
    "## Loading the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7c3d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "df_xgb = pd.read_csv(\"../data/features/features_XGBOOST.csv\")\n",
    "df_mlp = pd.read_csv(\"../data/features/features_MLP.csv\")\n",
    "df_lstm = pd.read_csv(\"../data/features/features_LSTM.csv\")\n",
    "\n",
    "print(\"Datasets loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22836f0",
   "metadata": {},
   "source": [
    "## Preparing Model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac24b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_split(df, target=\"target\", split=0.8):\n",
    "    split_idx = int(len(df) * split)\n",
    "    train = df.iloc[:split_idx]\n",
    "    test  = df.iloc[split_idx:]\n",
    "\n",
    "    X_train = train.drop(columns=[target])\n",
    "    y_train = train[target]\n",
    "\n",
    "    X_test = test.drop(columns=[target])\n",
    "    y_test = test[target]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d31765",
   "metadata": {},
   "source": [
    "## Training XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21aa051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb = df_xgb.drop(columns=[\"timestamp\"], errors=\"ignore\")\n",
    "\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = ts_split(df_xgb)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=350,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06246a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(X_train_xgb, y_train_xgb)\n",
    "\n",
    "pred_xgb = model_xgb.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b17c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 14.009238783888176\n",
      "XGBoost MAE : 10.98015790296999\n",
      "XGBoost R2  : 0.9213061049327921\n"
     ]
    }
   ],
   "source": [
    "# --- METRICS ---\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test_xgb, pred_xgb))\n",
    "mae_xgb = mean_absolute_error(y_test_xgb, pred_xgb)\n",
    "r2_xgb = r2_score(y_test_xgb, pred_xgb)\n",
    "\n",
    "print(\"XGBoost RMSE:\", rmse_xgb)\n",
    "print(\"XGBoost MAE :\", mae_xgb)\n",
    "print(\"XGBoost R2  :\", r2_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e3ebd",
   "metadata": {},
   "source": [
    "## Training Multi-Layer Perceptron (MLP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7bd943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\energy-forecasting\\venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_mlp = df_mlp.select_dtypes(include=[\"number\"])\n",
    "\n",
    "X_train_mlp, X_test_mlp, y_train_mlp, y_test_mlp = ts_split(df_mlp)\n",
    "\n",
    "# Scale tabular data\n",
    "scaler_mlp = StandardScaler()\n",
    "X_train_mlp_scaled = scaler_mlp.fit_transform(X_train_mlp)\n",
    "X_test_mlp_scaled  = scaler_mlp.transform(X_test_mlp)\n",
    "\n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(X_train_mlp_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa2b324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 19514.2344\n",
      "Epoch 2/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 794.1052\n",
      "Epoch 3/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.9674\n",
      "Epoch 4/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 612.7626\n",
      "Epoch 5/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 578.4688\n",
      "Epoch 6/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 544.9061\n",
      "Epoch 7/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 528.8756\n",
      "Epoch 8/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 506.3365\n",
      "Epoch 9/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 497.9416\n",
      "Epoch 10/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 461.4678\n",
      "Epoch 11/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 454.5944\n",
      "Epoch 12/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 450.2085\n",
      "Epoch 13/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 440.7553\n",
      "Epoch 14/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 420.9569\n",
      "Epoch 15/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 417.1037\n",
      "Epoch 16/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 405.3682\n",
      "Epoch 17/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 399.8973\n",
      "Epoch 18/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 394.5058\n",
      "Epoch 19/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 389.0732\n",
      "Epoch 20/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 386.3604\n",
      "Epoch 21/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 377.6516\n",
      "Epoch 22/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 372.9809\n",
      "Epoch 23/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 373.8778\n",
      "Epoch 24/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 368.9443\n",
      "Epoch 25/25\n",
      "\u001b[1m654/654\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 359.4043\n",
      "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "mlp_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "mlp_model.fit(X_train_mlp_scaled, y_train_mlp, epochs=25, batch_size=32, verbose=1)\n",
    "\n",
    "pred_mlp = mlp_model.predict(X_test_mlp_scaled).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e7158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP RMSE: 14.249074915812807\n",
      "MLP MAE : 11.074252135452086\n",
      "MLP R2  : 0.9185885844915481\n"
     ]
    }
   ],
   "source": [
    "# --- METRICS ---\n",
    "rmse_mlp = np.sqrt(mean_squared_error(y_test_mlp, pred_mlp))\n",
    "mae_mlp = mean_absolute_error(y_test_mlp, pred_mlp)\n",
    "r2_mlp = r2_score(y_test_mlp, pred_mlp)\n",
    "\n",
    "print(\"MLP RMSE:\", rmse_mlp)\n",
    "print(\"MLP MAE :\", mae_mlp)\n",
    "print(\"MLP R2  :\", r2_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70048d90",
   "metadata": {},
   "source": [
    "## Training LSTM (Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89be9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Feature Columns\n",
    "lstm_features = [\n",
    "    \"energy_consumption\",\n",
    "    \"temperature_C\",\n",
    "    \"humidity_pct\",\n",
    "    \"hour_sin\", \"hour_cos\",\n",
    "    \"dow_sin\", \"dow_cos\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9b88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 24  # 24 hours sequence\n",
    "\n",
    "# Convert to numpy\n",
    "data = df_lstm[lstm_features + [\"target\"]].values\n",
    "\n",
    "# Scale entire thing (LSTM friendly)\n",
    "scaler_lstm = MinMaxScaler()\n",
    "data_scaled = scaler_lstm.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6b4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "X_lstm, y_lstm = [], []\n",
    "for i in range(len(data_scaled) - SEQ_LEN):\n",
    "    X_lstm.append(data_scaled[i:i+SEQ_LEN, :-1])\n",
    "    y_lstm.append(data_scaled[i+SEQ_LEN, -1])\n",
    "\n",
    "X_lstm = np.array(X_lstm)\n",
    "y_lstm = np.array(y_lstm)\n",
    "\n",
    "# Split\n",
    "split = int(len(X_lstm) * 0.8)\n",
    "X_train_lstm, X_test_lstm = X_lstm[:split], X_lstm[split:]\n",
    "y_train_lstm, y_test_lstm = y_lstm[:split], y_lstm[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33be98a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\energy-forecasting\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0068\n",
      "Epoch 2/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0023\n",
      "Epoch 3/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0019\n",
      "Epoch 4/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0017\n",
      "Epoch 5/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0016\n",
      "Epoch 6/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0016\n",
      "Epoch 7/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0015\n",
      "Epoch 8/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015\n",
      "Epoch 9/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014\n",
      "Epoch 10/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014\n",
      "Epoch 11/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014\n",
      "Epoch 12/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014\n",
      "Epoch 13/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014\n",
      "Epoch 14/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014\n",
      "Epoch 15/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013\n",
      "Epoch 16/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014\n",
      "Epoch 17/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014\n",
      "Epoch 18/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013\n",
      "Epoch 19/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013\n",
      "Epoch 20/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013\n",
      "Epoch 21/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013\n",
      "Epoch 22/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013\n",
      "Epoch 23/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013\n",
      "Epoch 24/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013\n",
      "Epoch 25/25\n",
      "\u001b[1m653/653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013\n",
      "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, return_sequences=False, input_shape=(SEQ_LEN, X_train_lstm.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=25, batch_size=32, verbose=1)\n",
    "\n",
    "pred_lstm_scaled = lstm_model.predict(X_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45a8b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse scale target column only\n",
    "dummy = np.zeros((len(pred_lstm_scaled), data_scaled.shape[1]))\n",
    "dummy[:, -1] = pred_lstm_scaled.flatten()\n",
    "pred_lstm = scaler_lstm.inverse_transform(dummy)[:, -1]\n",
    "\n",
    "# True values\n",
    "dummy2 = np.zeros((len(y_test_lstm), data_scaled.shape[1]))\n",
    "dummy2[:, -1] = y_test_lstm.flatten()\n",
    "true_lstm = scaler_lstm.inverse_transform(dummy2)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b2e5a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM RMSE: 16.029500454050982\n",
      "LSTM MAE : 12.563146805207172\n",
      "LSTM R2  : 0.8968897594981229\n"
     ]
    }
   ],
   "source": [
    "# --- METRICS ---\n",
    "rmse_lstm = np.sqrt(mean_squared_error(true_lstm, pred_lstm))\n",
    "mae_lstm = mean_absolute_error(true_lstm, pred_lstm)\n",
    "r2_lstm = r2_score(true_lstm, pred_lstm)\n",
    "\n",
    "print(\"LSTM RMSE:\", rmse_lstm)\n",
    "print(\"LSTM MAE :\", mae_lstm)\n",
    "print(\"LSTM R2  :\", r2_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bda5122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "       ğŸ“Š FINAL MODEL SCORES\n",
      "====================================\n",
      "LSTM     â†’ RMSE: 16.0295, MAE: 12.5631, RÂ²: 0.8969\n",
      "XGBoost  â†’ RMSE: 14.0092, MAE: 10.9802, RÂ²: 0.9213\n",
      "MLP      â†’ RMSE: 14.2491, MAE: 11.0743, RÂ²: 0.9186\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n====================================\")\n",
    "print(\"       ğŸ“Š FINAL MODEL SCORES\")\n",
    "print(\"====================================\")\n",
    "\n",
    "print(f\"LSTM     â†’ RMSE: {rmse_lstm:.4f}, MAE: {mae_lstm:.4f}, RÂ²: {r2_lstm:.4f}\")\n",
    "print(f\"XGBoost  â†’ RMSE: {rmse_xgb:.4f}, MAE: {mae_xgb:.4f}, RÂ²: {r2_xgb:.4f}\")\n",
    "print(f\"MLP      â†’ RMSE: {rmse_mlp:.4f}, MAE: {mae_mlp:.4f}, RÂ²: {r2_mlp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b676e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST MODEL BASED ON RMSE: XGBoost\n"
     ]
    }
   ],
   "source": [
    "model_scores = {\n",
    "    \"LSTM\": rmse_lstm,\n",
    "    \"XGBoost\": rmse_xgb,\n",
    "    \"MLP\": rmse_mlp\n",
    "}\n",
    "\n",
    "best_model_name = min(model_scores, key=model_scores.get)\n",
    "print(\"\\nBEST MODEL BASED ON RMSE:\", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aca1d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Saved best model: ../models/best_model.pkl (XGBoost)\n"
     ]
    }
   ],
   "source": [
    "if best_model_name == \"XGBoost\":\n",
    "    joblib.dump(model_xgb, \"../models/best_model.pkl\")\n",
    "    joblib.dump(scaler_mlp, \"../models/best_scaler.pkl\")   # optional if using ML scaler\n",
    "    print(\"âœ” Saved best model: ../models/best_model.pkl (XGBoost)\")\n",
    "\n",
    "elif best_model_name == \"MLP\":\n",
    "    mlp_model.save(\"../models/best_model.h5\")\n",
    "    joblib.dump(scaler_mlp, \"../models/best_scaler.pkl\")\n",
    "    print(\"âœ” Saved best model: ../models/best_model.h5 (MLP)\")\n",
    "\n",
    "elif best_model_name == \"LSTM\":\n",
    "    lstm_model.save(\"../models/best_model.h5\")\n",
    "    joblib.dump(scaler_lstm, \"../models/best_scaler.pkl\")\n",
    "    print(\"âœ” Saved best model: ../models/best_model.h5 (LSTM)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
